---
title: |
 Individualized treatment effect was predicted best by modelin
 baseline risk in interaction with treatment assignment
abstract: |
author:
  - Alexandros Rekkas$^1$,
  - Peter R. Rijnbeek$^1$,
  - David M. Kent$^2$,
  - Ewout W. Steyerberg$^3$,
  - David van Klaveren$^4$
numbersections: true
linenumbers: false
output:
  bookdown::pdf_document2: default
  bookdown::word_document2:
    reference_docx: reference.docx
geometry: margin=1.0in
date: false
toc: false
font-size: 11pt
header-includes:
  - \renewcommand*\familydefault{\sfdefault}
  - \usepackage{setspace}
  - \usepackage[left, pagewise]{lineno}
  - \usepackage{caption}
  - \usepackage{amsmath}
  - \doublespacing
  - \usepackage{amssymb}
  - \usepackage{bm}
  - \usepackage{booktabs}
  - \date{}
  - \newcommand\given[1][]{\:#1\vert\:}
  - \newcommand{\indep}{\perp \!\!\! \perp}
editor_options: 
  chunk_output_type: console
bibliography: references.bib
csl: jce.csl
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
library(SmoothHte)
library(rms)
library(here)

d <- function(x, decimals = 4) {
  sprintf(paste0("%1.", decimals, "f"), x) 
}

inline_hook <- function(x) {
  if (is.numeric(x)) {
    if (abs(x - round(x)) < .Machine$double.eps) {
      formatted <- format(x, digits = 1, big.mark = ",")
    } else {
      formatted <- format(x, digits = 1 ,nsmall = 3, big.mark = ",")
    }
  } else {
    formatted <- x
  }
  
  return(formatted)
}

knit_hooks$set(inline = inline_hook)

  

set.seed(19910930)
```

\thispagestyle{empty}
\vspace{8mm}

$^1$ Department of Medical Informatics, Erasmus Medical Center, Rotterdam, The Netherlands

$^2$ Predictive Analytics and Comparative Effectiveness Center, Institute for Clinical Research and Health Policy Studies, Tufts Medical Center, Boston, Massachusetts, USA

$^3$ Department of Biomedical Data Sciences, Leiden University Medical Center, Leiden, The Netherlands

$^4$ Department of Public Health, Erasmus Medical Center, Rotterdam, The Netherlands


\vspace{10mm}
**Corresponding author**
\singlespacing 
Alexandros Rekkas, MSc

Department of Medical Informatics

Erasmus University Medical Center

3000 CA Rotterdam, P.O. Box 2040

Email: a.rekkas@erasmusmc.nl
\onehalfspacing

\vspace{10mm}
**Funding**

This work has been performed in the European Health Data and
Evidence Network (EHDEN) project. This project has received funding from the
Innovative Medicines Initiative 2 Joint Undertaking (JU) under grant agreement
No 806968. The JU receives support from the European Union’s Horizon 2020
research and innovation programme and EFPIA.

\newpage
\newpage

# Abstract {-}
**Objective**: To compare different risk-based methods for optimal prediction
of treatment effects. **Study Design and Setting**: We simulated RCT data
using diverse assumptions for the average treatment effect, a baseline
prognostic index of risk (PI), the shape of its interaction with treatment
(none, linear, quadratic or non-monotonic), and the magnitude of
treatment-related harms (none or constant independent of the PI). We predicted
absolute benefit using: models with a constant relative treatment effect;
stratification in quarters of the PI; models including a linear interaction of
treatment with the PI; models including an interaction of treatment with a
restricted cubic spline (RCS) transformation of the PI; an adaptive approach
using Akaike’s Information Criterion. We evaluated predictive performance
using root mean squared error and measures of discrimination and calibration
for benefit. **Results**: The linear-interaction model displayed optimal or
close-to-optimal performance across many simulation scenarios with moderate
sample size (N=4,250; ~785 events). The RCS-model was optimal for strong
non-linear deviations from a constant treatment effect, particularly when
sample size was larger (N=17,000). The adaptive approach also required larger
sample sizes. These findings were illustrated in the GUSTO-I
trial. **Conclusion**: An interaction between baseline risk and treatment
assignment should be considered to improve treatment effect predictions.

\vspace{10mm}

**Keywords**: treatment effect heterogeneity, absolute benefit, prediction models

\newpage

\doublespacing 

# Introduction
Predictive approaches to heterogeneity of treatment effects (HTE) aim at the
development of models predicting either individualized effects or which of two
(or more) treatments is better for an individual 

:::{custom-style="bluefont"}
with regard to a specific outcome of interest
:::

[@Varadhan2013]. In prior work, we divided such
methods in three broader categories based on the reference
class

:::{custom-style="bluefont"}
, i.e. the set of covariates} used for defining patient
:::

similarity when making individualized predictions or recommendations
[@Rekkas2020]. ~~Risk-modeling approaches use prediction of baseline risk as the
reference;~~ 

:::{custom-style="bluefont"}
Risk modeling methods predict similar treatment benefits for patients with
similar baseline outcome risk, i.e. the probability of a certain patient
experiencing the outcome of interest under the control;
:::

treatment effect modeling approaches also model treatment-covariate
interactions, in addition to risk factors; optimal treatment regime approaches
focus on developing treatment assignment rules and rely heavily on modeling
treatment effect modifiers.

Risk-modeling approaches to predictive HTE analyses provide a viable option in
the absence of well-established treatment effect modifiers [@Kent2019;
@PathEnE].

:::{custom-style="bluefont"}
Risk modeling approaches are not new [@Rekkas2020] and are quite intuitive to
practitioners. Often medical guidelines rely on a risk stratified approach to
target treatments to different patients. In addition, re-analyses of studies
that only looked at overall results using risk stratification often result to
important insight on how treatment effects varied for diffrent patients. For
example, a risk stratified analysis of patients with acute myocardial infarction
(MI) based on the Thrombolysis in Myocardial Infarction (TIMI) risk score found
no benefit for patients who underwent primary angioplasty compared to
fibrynolysis. However, there was a significant benefit for patients with a high
TIMI score [@Thune2005]. Infants at lower risk of bronchopulmonary dysplasia
benefit relatively more from vitamin A therapy than infants at higher risk
[@Rysavy2021]. Finally, higher risk prediabetic patients benefit relatively more
from metformin than lower risk patients [@Sussman2015].
:::

:::{custom-style="bluefont"}
They result in increased power for detecting HTE, as they
evaluate interactions of treatment with a summary score, i.e. baseline outcome
risk, and, thus, avoid modeling treatment-covariate interactions.
:::

In simulations, modeling treatment-covariate interactions, often led to
miscalibrated predictions of ~~absolute benefit~~ 

:::{custom-style="bluefont"}
benefit on
the absolute scale (risk difference), ~~contrary~~ compared
:::

to risk-modeling methods~~, despite their weaker discrimination of benefit in
the presence of true effect modifiers~~
[@vanKlaveren2019]. 

:::{custom-style="bluefont"}
However, in the presence of true
treatment-covariate interactions, risk modeling methods performed worse in
separating lower from higher benefit patients compared to treatment effect
modeling methods.
:::

Most often, risk-modeling approaches are carried out in two
steps: first a risk prediction model is developed externally or internally on
the entire RCT population, “blinded” to treatment; then the RCT population is
stratified using this prediction model to evaluate risk-based treatment effect
variation [@Kent2010]. This approach identified substantial absolute treatment
effect differences between low-risk and high-risk patients in a re-analysis of
32 large trials [@Kent2016]. However, even though 

:::{custom-style="bluefont"}
treatment effect estimates at the risk subgroup level may be accurate, these
estimates may not apply to individual patients,{as homogeneity of treatment
effects is assumed within risk strata. With stronger treatment effect
heterogeneity (larger variability between estimated risk-subgroup treatment
effects), predicted treatment effects for patients with similar predicted risk
may be quite different, if they end up in different risk strata.
:::

In the current simulation study, we aim to summarize and compare different
risk-based models for predicting treatment effects. We simulate different
relations between baseline risk and treatment effects and also consider
potential harms of treatment. We illustrate the different models by a case study
of predicting individualized effects of treatment for acute myocardial
infarction ~~(MI)~~in a large RCT.


# Methods

## Notation

We observe RCT data $(Z, X, Y)$, where for each patient $Z_i= 0, 1$ is the
treatment status, $Y_i = 0, 1$ is the observed outcome and $X_i$ is a set of
measured covariates. Let $\{Y_i(z), z=0, 1\}$ denote the unobservable potential
outcomes. We observe $Y_i = Z_iY_i(1) + (1 - Z_i)Y_i(0)$. We are interested in
predicting the conditional average treatment effect (CATE), 
$$\tau(x) = E\{Y(0) - Y(1)|X=x\}$$ 
Assuming that $\big(Y(0), Y(1)\big)\indep Z|X$, as we are in the RCT setting, we
can predict CATE from
\begin{align*}
\tau(x) &= E\{Y(0)\given X=x\}-E\{Y(1)\given X=x\}\\
&=E\{Y\given X=x, Z=0\}-E\{Y\given X=x, Z=1\}
\end{align*}

## Simulation scenarios

We simulated a typical RCT, comparing equally-sized treatment and control arms
in terms of a binary outcome. For each patient we generated 8 baseline
covariates $x_1,\dots,x_4\sim N(0, 1)$ and $x_5,\dots,x_8\sim
B(1,0.2)$. Outcomes in the control arm were generated from Bernoulli variables
with true probabilities following a logistic regression model including all
baseline covariates, i.e.  $P(Y(0)=1\given X=x) = \text{expit}(lp_0) =
e^{lp_0}/(1+e^{lp_0})$, with $lp_0=lp_0(x)=x^t\beta$.  In the base scenarios
coefficient values $\beta$ were such, that the ~~AUC of the logistic regression
model was 0.75 and the event rate in the control arm was
$20\%$.~~

:::{custom-style="bluefont"}
the control event rate was 20\% and the discriminative
ability of the true prediction model measured using Harrell's c-statistic was
0.75. The c-statistic represents the probability that for a randomly selected
discordant pair from the sample (patients with different outcomes) the
prediction model assigns larger risk to the patient with the worse outcome. For
the simulations this was achieved by selecting $\beta$ values such that the true
prediction model would achieve a c-statistic of 0.75 in a simulated control arm
with 1,000,000 patients. In the base case scenario we achieved that by setting
$\beta=(-2.08, 0.49,\dots,0.49)^t$.
:::

Outcomes in the treatment arm were first generated using 3 simple scenarios:
absent (OR = 1), moderate (OR = 0.8) or strong (OR = 0.5) constant relative
treatment effect. We then introduced linear, quadratic and non-monotonic
deviations from constant treatment effects using: $$lp_1 = \gamma_0 +
\gamma_1(lp_0-c) + \gamma_2(lp_0-c)^2, $$ where $lp_1$ is the true linear
predictor in the treatment arm, so that $P(Y(1)=1\given X=x) =
\text{expit}(lp_1)$, 

:::{custom-style="bluefont"}
$\gamma=(\gamma_0, \gamma_1, \gamma_2)^t$
controls the shape of evolution of treatment effect as a function of baseline
risk (type and strength of deviations from the constant treatment effect
setting), while $c$ allows us to shift the proposed shape function to achieve
the desired overall event rates. For example, to simulate a constant treatment
effect with $\text{OR}=0.8$ we would set $\gamma=(\log(0.8), 1, 0)^t$ and
$c=0$.
:::

Finally, we incorporated constant absolute harms for all treated
patients, such that $P(Y(1)=1|X=x) = \text{expit}(lp_1) + \text{harm}$.

The sample size for the base scenarios was set to 4,250 (80\% power for the
detection of a marginal OR of 0.8 ~~with the standard alpha of 5\%~~

:::{custom-style="bluefont"}
using a 5\% significance level for the Wald test for the treatment coefficient
in a logistic regression model).
:::

We evaluated the
~~effect~~ 

:::{custom-style="bluefont"}
impact
:::

of smaller or larger sample sizes of 1,063
and 17,000, respectively. We also evaluated the ~~effect~~

:::{custom-style="bluefont"}
impact
:::

of risk model discriminative ability, adjusting the
baseline covariate coefficients, such that the AUC of the regression model in
the control arm was 0.65 and 0.85, respectively.

These settings resulted in a simulation study of 648 scenarios covering the
HTE observed in 32 large trials as well as many other potential variations of
risk-based treatment effect (Supplement, Sections 2 and 3) [@Kent2016].
 
## Individualized risk-based benefit predictions

In each simulation run we internally developed a prediction model on the entire
population, using a logistic regression with main effects for all baseline
covariates and treatment assignment. Individual risk predictions were derived by
setting treatment assignment to 0. Another approach would be to derive the
prediction model solely on the control patients; however, it has been shown to
lead to biased benefit predictions [@vanKlaveren2019; @Burke2014; @Abadie2018].

A *stratified HTE method* has been suggested as an alternative to traditional
subgroup analyses [@Kent2019; @PathEnE]. Patients are stratified into
equally-sized risk strata—in this case based on risk quartiles. Absolute
treatment effects within risk strata are estimated by the difference in event
rate between control and treatment arm patients. We considered this approach as
a reference, expecting it to perform worse than the other candidates, as its
objective is to provide an illustration of HTE rather than to optimize
individualized benefit predictions.

Second, we ~~considered~~ 

:::{custom-style="bluefont"}
fitted
:::

a 

:::{custom-style="bluefont"}
logistic regression 
:::

model which assumes *constant relative treatment effect* (constant
odds ratio) 

:::{custom-style="bluefont"}
, that is, $P(Y=1\given X=x, Z=z;\hat{\beta}) =
\text{expit}(\hat{lp}_0 + \delta_0z)$.
:::

Hence, absolute benefit is predicted
from $\tau(x;\hat{\beta}) = \text{expit}(\hat{lp}_0) -
\text{expit}(\hat{lp}_0+\delta_0)$, where $\delta_0$ is the log of the assumed
constant odds ratio and $\hat{lp}_0 = \hat{lp}_0(x;\hat{\beta}) =
x^t\hat{\beta}$ the linear predictor of the estimated baseline risk model.

Third, we ~~considered~~ 

:::{custom-style="bluefont"}
fitted
:::

a logistic regression model
including treatment, the prognostic index, and their linear interaction

:::{custom-style="bluefont"}
, that is, $P(Y=1\given X=x, Z=z;\hat{\beta}) =
\text{expit}(\delta_0+\delta_1z+\delta_2
\hat{lp}_0+\delta_3z\hat{lp}_0)$
:::

Absolute benefit is then estimated from
$\tau(x;\hat{\beta}) = \text{expit}(\delta_0+\delta_1\hat{lp}_0) -
\text{expit}(\delta_0 + \delta_1\hat{lp}_0 + \delta_2z+\delta_3z\hat{lp}_0)$. We
will refer to this method as the *linear interaction* approach.

Fourth, we used *restricted cubic splines* (RCS) to relax the linearity
assumption on the effect of the linear predictor [@Harrell1988]. We considered
splines with 3 (RCS-3), 4 (RCS-4) and 5 (RCS-5) knots to compare models with
different levels of flexibility.

Finally, we considered an adaptive approach using Akaike’s Information Criterion
(AIC) for model selection. More specifically, we ranked the constant relative
treatment effect model, the linear interaction model, and the RCS models with 3,
4, and 5 knots based on their AIC and selected the one with the lowest
value. The extra degrees of freedom were 1 (linear interaction), 2, 3 and 4 (RCS
models) for these increasingly complex interactions with the treatment effect.

## Evaluation metrics
We evaluated the predictive accuracy of the considered methods by the root mean
squared error (RMSE):

$$\text{RMSE}=\sqrt{\frac{1}{n}\sum_{i=1}^n\big(\tau(\bm{x}_i) - \hat{\tau}(\bm{x}_i)\big)^2}$$

We compared the discriminative ability of the methods under study using
c-for-benefit and the integrated calibration index (ICI) for
benefit ~~(Supplement, section 6)~~.

:::{custom-style="bluefont"}
The c-for-benefit represents the probability that from two randomly chosen
matched patient pairs with unequal observed benefit, the pair with greater
observed benefit also has a higher predicted benefit. To be able to calculate
observed benefit, patients in each treatment arm are ranked based on their
predicted benefit and then matched 1:1 across treatment arms. Observed treatment
benefit is defined as the difference of observed outcomes between the untreated
and the treated patient of each matched patient pair. Predicted benefit is
defined as the average of predicted benefit within each matched patient pair
[@vanKlaveren2018].
:::

:::{custom-style="bluefont"}
We evaluated calibration in a similar manner, using the integrated calibration
index (ICI) for benefit [@Austin2019]. The observed benefits are regressed on
the predicted benefits using a locally weighted scatterplot smoother
(loess). The ICI-for-benefit is the average absolute difference between
predicted and smooth observed benefit. Values closer to represent better
calibration.
:::

For each scenario we performed 500 replications, within which all the considered
models were fitted. We simulated a super-population of size 500,000 for each
scenario within which we calculated RMSE and discrimination and calibration for
benefit of all the models in each replication.

## Empirical illustration

```{r, echo=FALSE, warning=FALSE, message=FALSE}
load(here::here("data/raw/gusto.rda"))
gusto <- gusto %>%
  tibble() %>%
  filter(!is.na(tpa))

gusto <- gusto %>%
  tibble() %>%
  filter(tx != "SK+tPA") %>%
  rename(
    "outcome" = "day30",
    "treatment" = "tpa"
  )

treatmentArms <- gusto %>%
  group_by(treatment) %>%
  summarise(n = n())
```

We demonstrated the different methods using `r nrow(gusto)` patients with acute
myocardial infarction (MI) included in the GUSTO-I trial.  `r treatmentArms %>%
filter(treatment == 1) %>% pull(n)` patients were randomized to tissue
plasminogen activator (tPA) treatment and `r treatmentArms %>% filter(treatment
== 0) %>% pull(n)` were randomized to streptokinase. The outcome of interest was
30-day mortality (total of `r sum(gusto$outcome)` events), recorded for all
patients. 

:::{custom-style="bluefont"}
This dataset has been used extensively in prior studies
:::

~~In line with previous analyses~~ [@Califf1997; @Steyerberg2000]

:::{custom-style="bluefont"}
Therefore, we used the same set of 7 covariates that was previously used to,
:::

~~we fitted~~ 

:::{custom-style="bluefont"}
fit
:::

a logistic regression
model with ~~6~~ 

:::{custom-style="bluefont"}
the following
:::

baseline covariates: age, Killip class, systolic blood pressure, heart rate, an
indicator of previous MI, and the location of MI, to predict 30-day mortality
risk (Supplement, Section 8).

# Results

## Simulations

```{r adaptive, echo=FALSE, warning=FALSE, message=FALSE}
adaptiveSelections <- readr::read_csv(here::here("data/processed/adaptiveSelections.csv"))
rmseDistribution <- readr::read_csv(here::here("data/processed/rmseDistribution.csv"))
aucDistribution <- readr::read_csv(here::here("data/processed/discriminationDistribution.csv"))
```

```{r rmse, echo=FALSE, warning=FALSE, message=FALSE}
analysisIds <- readr::read_csv(here::here("data/processed/analysisIds.csv"))
rmse <- readr::read_csv(here::here("data/processed/rmse.csv"))
selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "constant",
    sampleSize == 4250,
    auc == 0.75,
    harm == "absent"
  ) %>%
  dplyr::pull(scenario)

rmseBaseCase <- rmse %>% dplyr::filter(scenarioId == selectedScenario)

selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "linear-high",
    sampleSize == 4250,
    auc == 0.75,
    harm == "absent"
  ) %>%
  dplyr::pull(scenario)

rmseLinearInteraction <- rmse %>% dplyr::filter(scenarioId == selectedScenario)

selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "quadratic-high",
    sampleSize == 4250,
    auc == 0.75,
    harm == "absent"
  ) %>%
  dplyr::pull(scenario)

rmseQuadratic <- rmse %>% dplyr::filter(scenarioId == selectedScenario)

selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "non-monotonic",
    sampleSize == 4250,
    auc == 0.75,
    harm == "absent"
  ) %>%
  dplyr::pull(scenario)

rmseNonMonotonic <- rmse %>% dplyr::filter(scenarioId == selectedScenario)

selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "non-monotonic",
    sampleSize == 4250,
    auc == 0.75,
    harm == "strong-positive"
  ) %>%
  dplyr::pull(scenario)

rmseNonMonotonicHarm <- rmse %>% dplyr::filter(scenarioId == selectedScenario)
```

The constant treatment effect approach outperformed other approaches in the base
case scenario (N = `r 4250`; OR = 0.8; AUC= 0.75; no absolute treatment harm)
with a true constant treatment effect (median RMSE: constant treatment effect 
`r median(rmseBaseCase$constant_treatment_effect)`;
linear interaction `r median(rmseBaseCase$linear_predictor)`;
RCS-3 `r median(rmseBaseCase$rcs_3_knots)`). 
The linear interaction model was optimal under true linear deviations 
(median RMSE: constant treatment effect 
`r median(rmseLinearInteraction$constant_treatment_effect)`;
linear interaction `r median(rmseLinearInteraction$linear_predictor)`;
RCS-3 `r median(rmseLinearInteraction$rcs_3_knots)`; Figure \ref{fig:rmsebase} panels A-C)
and even in the presence of true quadratic deviations
(median RMSE: constant treatment effect 
`r median(rmseQuadratic$constant_treatment_effect)`;
linear interaction `r median(rmseQuadratic$linear_predictor)`;
RCS-3 `r median(rmseQuadratic$rcs_3_knots)`; Figure \ref{fig:rmsebase} panels A-C)
from a constant relative treatment effect. With non-monotonic deviations, RCS-3
slightly outperformed the linear interaction model
(median RMSE: linear interaction `r median(rmseNonMonotonic$linear_predictor)`;
RCS-3 `r median(rmseNonMonotonic$rcs_3_knots)`; Figure \ref{fig:rmsebase} panel D).
With strong treatment-related harms the results were very similar in most
scenarios (Figure \ref{fig:rmsebase} panels A-C). Under non-monotonic deviations
the optimal performance of RCS-3 was more pronounced
(median RMSE: linear interaction `r median(rmseNonMonotonicHarm$linear_predictor)`;
RCS-3 `r median(rmseNonMonotonicHarm$rcs_3_knots)`; Figure \ref{fig:rmsebase} panel D).
A stronger average treatment effect (OR=0.5) 

:::{custom-style="bluefont"}
resulted in higher variability of the true treatment effects on the absolute
scale (difference in true outcome probabilities between treatment arms)
:::

~~led to larger absolute benefit
predictions~~ and consequently to larger RMSE for all approaches. ~~but~~ 

:::{custom-style="bluefont"}
However,
:::

the relative differences between different approaches were similar to the base case scenario
(Supplement, Figure S10). 
```{r rmsebase, cache=TRUE, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated from a simulated super-population of size 500,000. The scenario with true constant relative treatment effect (panel A) had a true prediction AUC of 0.75 and sample size of 4250. The RMSE is also presented for strong linear (panel B), strong quadratic (panel C), and non-monotonic (panel D) from constant relative treatment effects. Panels on the right side present the true relations between baseline risk (x-axis) and absolute treatment benefit (y-axis). The 2.5, 25, 50, 75, and 97.5 percentiles of the risk distribution are expressed by the boxplot on the top. The 2.5, 25, 50, 75, and 97.5 percentiles of the true benefit distributions are expressed by the boxplots on the side of the right-handside panel.", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/rmse_moderate_base.tiff")))
# knitr::include_graphics(here::here("figures/rmse_base.png"))
```

The adaptive approach had limited loss of performance in terms of the median
RMSE to the best-performing method in each scenario. However, compared to the
best-performing approach, its RMSE was more variable in scenarios with linear
and non-monotonic deviations, especially when also including moderate or strong
treatment-related harms. On closer inspection, we found that this behavior was
caused by selecting the constant treatment effect model in a substantial
proportion of the replications (Supplement, Figure S3).

```{r rmseSamplesize, echo=FALSE, warning=FALSE, message=FALSE}
selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "constant",
    sampleSize == 17000,
    auc == 0.75,
    harm == "absent"
  ) %>%
  dplyr::pull(scenario)

rmseBaseCaseSampleSize <- rmse %>% dplyr::filter(scenarioId == selectedScenario)

selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "linear-high",
    sampleSize == 17000,
    auc == 0.75,
    harm == "absent"
  ) %>%
  dplyr::pull(scenario)

rmseLinearInteractionSampleSize <- rmse %>% dplyr::filter(scenarioId == selectedScenario)

selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "quadratic-high",
    sampleSize == 17000,
    auc == 0.75,
    harm == "absent"
  ) %>%
  dplyr::pull(scenario)

rmseQuadraticSampleSize <- rmse %>% dplyr::filter(scenarioId == selectedScenario)

selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "non-monotonic",
    sampleSize == 17000,
    auc == 0.75,
    harm == "absent"
  ) %>%
  dplyr::pull(scenario)

rmseNonMonotonicSampleSize <- rmse %>% dplyr::filter(scenarioId == selectedScenario)
```

Increasing the sample size to `r 17000` favored RCS-3 the most (Figure
\ref{fig:rmsesamplesize}). The difference in performance with the linear
interaction approach was more limited in settings with a constant treatment
effect
(median RMSE: linear interaction `r median(rmseBaseCaseSampleSize$linear_predictor)`;
RCS-3 `r median(rmseBaseCaseSampleSize$rcs_3_knots)`) and with a true linear interaction
(median RMSE: linear interaction `r median(rmseLinearInteractionSampleSize$linear_predictor)`;
RCS-3 `r median(rmseLinearInteractionSampleSize$rcs_3_knots)`)
and more emphasized in settings with strong quadratic deviations 
(median RMSE: linear interaction `r median(rmseQuadraticSampleSize$linear_predictor)`;
RCS-3 `r median(rmseQuadraticSampleSize$rcs_3_knots)`) and non-monotonic deviations
(median RMSE: linear interaction `r median(rmseNonMonotonicSampleSize$linear_predictor)`;
RCS-3 `r median(rmseNonMonotonicSampleSize$rcs_3_knots)`).
Due to the large sample size, the RMSE of the adaptive approach was even more
similar to the best-performing method, and the constant relative treatment
effect model was less often wrongly selected (Supplement, Figure S4).

```{r rmsesamplesize, cache=TRUE, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in simulated samples of size 17,000 rather than 4,250 in Figure \\ref{fig:rmsebase}. RMSE was calculated on a super-population of size 500,000", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/rmse_moderate_sample_size.tiff")))
# knitr::include_graphics(here::here("figures/rmse_sample_size.png"))
```


```{r rmseAuc, echo=FALSE, warning=FALSE, message=FALSE}
selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "constant",
    sampleSize == 4250,
    auc == 0.85,
    harm == "absent"
  ) %>%
  dplyr::pull(scenario)

rmseBaseCaseAuc <- rmse %>% dplyr::filter(scenarioId == selectedScenario)

selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "linear-high",
    sampleSize == 4250,
    auc == 0.85,
    harm == "absent"
  ) %>%
  dplyr::pull(scenario)

rmseLinearInteractionAuc <- rmse %>% dplyr::filter(scenarioId == selectedScenario)

selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "quadratic-high",
    sampleSize == 4250,
    auc == 0.75,
    harm == "absent"
  ) %>%
  dplyr::pull(scenario)

rmseQuadraticAuc <- rmse %>% dplyr::filter(scenarioId == selectedScenario)

selectedScenario <- analysisIds %>%
  dplyr::filter(
    base == "moderate",
    type == "non-monotonic",
    sampleSize == 4250,
    auc == 0.75,
    harm == "absent"
  ) %>%
  dplyr::pull(scenario)

rmseNonMonotonicAuc <- rmse %>% dplyr::filter(scenarioId == selectedScenario)
```


Similarly, when we increased the AUC of the true prediction model to 0.85 (OR =
0.8 and N = 4,250), RCS-3 had the lowest RMSE in the case of strong quadratic or
non-monotonic deviations and very comparable performance to the – optimal –
linear interaction model in the case of strong linear deviations (median RMSE of
`r median(rmseLinearInteractionAuc$rcs_3_knots)` for RCS-3 compared to 
`r median(rmseLinearInteractionAuc$linear_predictor)` for the linear interaction
model; Figure \ref{fig:rmseauc}). Similar to the base case scenario the adaptive
approach wrongly selected the constant treatment effect model
(`r adaptiveSelections %>% filter(scenarioId == 297) %>% pull(treatment) * 100`\%
and
`r adaptiveSelections %>% filter(scenarioId == 405) %>% pull(treatment) * 100`\%
of the replications in the
strong linear and non-monotonic deviation scenarios without treatment-related
harms, respectively), leading to increased variability of the RMSE (Supplement,
Figure S5).

```{r rmseauc, cache=TRUE, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in simulated samples 4,250. True prediction AUC of 0.85. RMSE was calculated on a super-population of size 500,000", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/rmse_moderate_auc.tiff")))
# knitr::include_graphics(here::here("figures/rmse_auc.png"))
```


    
With a true constant relative treatment effect, discrimination for benefit was
only slightly lower for the linear interaction model, but substantially lower
for the non-linear RCS approaches (Figure \ref{fig:discrimination}; panel
A). With strong linear or quadratic deviations from a constant relative
treatment effect, all methods discriminated quite similarly (Figure
\ref{fig:discrimination}; panels B-C). With non-monotonic deviations, the
constant effect model had much lower discriminative ability compared to all
other methods
(median AUC of 0.500 for the constant effects model,
`r aucDistribution %>% filter(scenarioId == 397) %>% pull(median_linear)`
for the linear interaction model and
`r aucDistribution %>% filter(scenarioId == 397) %>% pull(median_rcs_3)`
Figure \ref{fig:discrimination}; panel D).
The adaptive approach was unstable in terms of discrimination for benefit,
especially with treatment-related harms. With increasing number of RCS knots, we
observed decreasing median values and increasing variability of the
c-for-benefit in all scenarios. When we increased the sample size to 17,000 we
observed similar trends, however the performance of all methods was more stable
(Supplement, Figure S6). Finally, when we increased the true prediction AUC to
0.85 the adaptive approach was, again, more conservative, especially with
non-monotonic deviations and null or moderate treatment-related harms
(Supplement, Figure S5).

```{r discrimination, cache=TRUE, echo=FALSE, fig.cap="Discrimination for benefit of the considered methods across 500 replications calculated in a simulated samples of size 4,250 using the c-statistic for benefit. The c-statistic for benefit represents the probability that from two randomly chosen matched patient pairs with unequal observed benefit, the pair with greater observed benefit also has a higher predicted benefit. True prediction AUC of 0.75.", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/discrimination_moderate_base.tiff")))
# knitr::include_graphics(here::here("figures/discrimination_base.png"))
```

In terms of calibration for benefit, the constant effects model outperformed all
other models in the scenario with true constant treatment effects, but was
miscalibrated for all deviation scenarios (Figure \ref{fig:calibration}). The
linear interaction model showed best or close to best calibration across all
scenarios and was only outperformed by RCS-3 in the case of non-monotonic
deviations and treatment-related harms (Figure \ref{fig:calibration}; panel
D). The adaptive approach was worse calibrated under strong linear and
non-monotonic deviations compared to the linear interaction model and
RCS-3. When we increased the sample size to 17,000 (Supplement, Figure S6) or
the true prediction AUC to 0.85 (Supplement, Figure S7), RCS-3 was somewhat
better calibrated than the linear interaction model with strong quadratic
deviations.

```{r calibration, cache=TRUE, echo=FALSE, fig.cap="Calibration for benefit of the considered methods across 500 replications calculated in a simulated sample of size 500,000. True prediction AUC of 0.75 and sample size of 4,250.", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/calibration_moderate_base.tiff")))
# knitr::include_graphics(here::here("figures/calibration_base.png"))
```




The results from all individual scenarios can be explored online at
[https://mi-erasmusmc.shinyapps.io/HteSimulationRCT/](https://mi-erasmusmc.shinyapps.io/HteSimulationRCT/). Additionally,
all the code for the simulations can be found at
[https://github.com/mi-erasmusmc/HteSimulationRCT](https://github.com/mi-erasmusmc/HteSimulationRCT)


## Empirical illustration


```{r, echo=FALSE, warning=FALSE, message=FALSE}
gustoPerformance <- readr::read_csv(here::here("data/processed/gustoPerformanceMetrics.csv"))

discriminationPerformance <- gustoPerformance %>%
  select("discrimination")
calibrationPerformance <- gustoPerformance %>%
  select("calibration")
```

We used the derived prognostic index to fit a constant treatment effect, a
linear interaction and an RCS-3 model individualizing absolute benefit
predictions. Following our simulation results, RCS-4 and RCS-5 models were
excluded. Finally, an adaptive approach with the 3 candidate models was
applied. 

:::{custom-style="bluefont"}
Predicted absolute benefit was derived as the difference of predicted acute MI
risk between treatment arms, if all other predictors remained unchanged.
:::

All considered methods provided similar fits, predicting increasing

:::{custom-style="bluefont"}
absolute
:::

benefits for patients with higher baseline risk
predictions, and followed the evolution of the stratified estimates closely
(Figure \ref{fig:gusto}). The constant treatment effect model had somewhat lower
AIC compared to the linear interaction model (AIC:
`r gustoPerformance %>% filter(method == "constant treatment effect") %>% pull(aic) %>% round()` versus 
`r gustoPerformance %>% filter(method == "RCS smoothing with 3 knots") %>% pull(aic) %>% round()`),
equal cross-validated discrimination
(c-for-benefit:
`r gustoPerformance %>% filter(method == "constant treatment effect") %>% pull(discrimination)`),
and slightly better cross-validated calibration
(ICI-for benefit:
`r gustoPerformance %>% filter(method == "constant treatment effect") %>% pull(calibration)` versus 
`r gustoPerformance %>% filter(method == "RCS smoothing with 3 knots") %>% pull(calibration)`).
In conclusion, although the sample size (`r nrow(gusto)` patients; 
`r sum(gusto$outcome)` events) allowed for flexible modeling approaches, a 
simpler constant treatment effect model is adequate for predicting absolute
30-day mortality benefits of treatment with tPA in patients with acute MI.

```{r gusto, cache=TRUE, echo=FALSE, fig.cap="Individualized absolute benefit predictions based on baseline risk when using a constant treatment effect approach, a linear interaction approach and RCS smoothing using 3 knots. Risk stratified estimates of absolute benefit are presented within quartiles of baseline risk as reference. 95\\% confidence bands were generated using 10,000 bootstrap resamples, where the prediction model was refitted in each run to capture the uncertainty in baseline risk predictions.", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/gusto.tiff")))
# knitr::include_graphics(here::here("figures/gusto.png"))
```

# Discussion

The linear interaction and the RCS-3 models displayed very good performance
under many of the considered simulation scenarios. The linear interaction model
was optimal in cases with moderate sample sizes (4.250 patients; ~785 events)
and moderately performing baseline risk prediction models, that is, it had lower
RMSE, was better calibrated for benefit and had better discrimination for
benefit, even in scenarios with strong quadratic deviations. In scenarios with
true non-monotonic deviations, the linear interaction model was outperformed by
RCS-3, especially in the presence of treatment-related harms. Increasing the
sample size or the prediction model’s discriminative ability favored RCS-3,
especially in scenarios with strong non-linear deviations from a constant
treatment effect.

Our simulation results clearly express the trade-off between the advantages of
flexibly modeling the relationship between baseline risk and treatment effect
and the disadvantages of overfitting this relationship to the sample at hand. With
infinite sample size, the more flexible approach (here RCS) will be optimal, but
in practice, with limited sample size, parsimonious models may be
preferable. Even with the substantial sample size of our base case scenario, the
(less flexible) linear interaction model performed better than the (more
flexible) RCS approach for most simulation settings. The even less flexible
constant treatment effect model, however, was only optimal when the treatment
effect was truly constant. Moreover, the assumption of a constant treatment
effect may often be too strong [@Rothwell1995; @Kent2016].  ~~For example, infants
at lower risk of bronchopulmonary dysplasia benefit relatively more from vitamin
A therapy than infants at higher risk [@Rysavy2021]; higher risk prediabetic
patients benefit relatively more from metformin than lower risk patients
[@Sussman2015]. Hence, a linear interaction between baseline risk and the effect
of treatment may be the most sensible approach with moderate sample sizes.~~

RCS-4 and RCS-5 were too flexible in all considered scenarios, as indicated by
higher RMSE, increased variability of discrimination for benefit and worse
calibration of benefit predictions. Even with larger sample sizes and strong
quadratic or non-monotonic deviations, these more flexible methods did not
outperform the simpler RCS-3 approach. Higher flexibility may only be helpful
under more extreme patterns of HTE compared to the quadratic deviations
considered here. Considering interactions in RCS-3 models as the most complex
approach often may be reasonable.

:::{custom-style="bluefont"}
Our results can also be interpreted in terms of bias-variance trade-off. The
increasingly complex models considered allow for more degrees of freedom which,
in turn increase the variance of our absolute benefit estimates. However, as was
clear in our simulations, this increased complexity did not always result in
substantial decrease in bias, especially with lower sample sizes and weaker
treatment effects. Consequently, in most scenarios the simpler linear
interaction model achieved the best variance-bias balance and outperformed the
more complex RCS methods, even in the presence of non-linearity in the true
underlying relationship between baseline risk and treatment effect. Conversely,
the simpler constant treatment effect model was often heavily biased and, despite
its lower variance, was outperformed by the other methods in the majority of the
considered scenarios.
:::

Increasing the discriminative ability of the risk model reduced RMSE for all
methods. Higher discrimination translates in higher variability of predicted
risks, which, in turn, allows the considered methods to better capture absolute
treatment benefits. As a consequence, better risk discrimination also led to
higher discrimination between those with low or high benefit (as reflected in
values of c-for-benefit).

The adaptive approach had adequate median performance, following the “true”
model in most scenarios. With smaller sample sizes it tended to miss the
treatment-baseline risk interaction and selected simpler models (Supplement
Section 4). This conservative behavior resulted in increased RMSE variability in
these scenarios, especially with true strong linear or non-monotonic
deviations. Therefore, with smaller sample sizes the simpler linear interaction
model may be a safer choice for predicting absolute benefits, especially in the
presence of any suspected treatment-related harms.

One limitation is that we assumed treatment benefit to be a function of baseline
risk in the majority of the simulation scenarios. We attempted to expand our
scenarios by considering moderate and strong constant treatment-related harms,
applied on the absolute scale, in line with previous work [@Glasziou1995]. In a
limited set of scenarios with true interactions between treatment assignment and
covariates, our conclusions remained unchanged (Supplement, Section 7). Even
though the average error rates increased for all the considered methods, due to
the miss-specification of the outcome model, the linear interaction model had
the lowest error rates. RCS-3 had very comparable performance. The constant
treatment effect model was often biased, especially with moderate or strong
treatment-related harms. Future simulation studies could explore the effect of
more extensive deviations from risk-based treatment effects.

We only focused on risk-based methods, using baseline risk as a reference in a
two-stage approach to individualizing benefit predictions. However, there is a
plethora of different methods, ranging from treatment effect modeling to
tree-based approaches available in more recent literature [@Athey2019; @Lu2018;
@Wager2018; @powers2018some]. Many of these methods rely on incorporating
treatment-covariate interactions when predicting benefit. An important caveat of
such approaches is their sensitivity to overfitting, which may exaggerate the
magnitude of predicted benefits. 

:::{custom-style="bluefont"}
However, this can often be mitigated using methods such as cross-validation or
regularization that penalizes the effect of treatment-covariate
interactions. Therefore, in the presence of a limited set of true strong
treatment-covariate interactions and adequate sample size one would expect
treatment effect modeling methods to outperform risk modeling methods in a
head-to-head comparison. [GOES WITH PREVIOUS]

Nevertheless, in many cases treatment effect modifiers
are not known and the available sample size does not allow the exploration of a
large number of interaction effects. In these cases, risk modeling approaches
like the ones presented here can provide individualized benefit predictions that
improve on the "one-size-fits-all" overall RCT result. [GOES WITH NEXT]
:::

In a wide range of simulation settings, a
simpler risk modeling approach was consistently better calibrated for benefit
compared to more complex treatment effect modelling approaches
[@vanKlaveren2019]. Similarly, when SYNTAX score II, a model developed for
identifying patients with complex coronary artery disease that benefit more from
percutaneous coronary intervention or from coronary artery bypass grafting was
redeveloped using fewer treatment-covariate interactions had better external
performance compared to its predecessor [@farooq2013anatomical;
@takahashi2020redevelopment]. However, whether this remains the case in a range
of empirical settings still needs to be explored.

:::{custom-style="bluefont"}
Finally, in all our simulation scenarios we assumed all covariates to be
statistically independent. This can be viewed as a limitation of our extensive
simulation study, as this often is not the case in practice. However, our aim
was to evaluate how sample size and the discriminative ability of the prediction
model affect the predictive performance of increasingly complex regression-based
methods for individualizing treatment effects. In this regard, that statistical
independence of the simulated covariates allows for cleaner interpretation of
the results. [I don't like that!!]
:::

In conclusion, the linear interaction approach is a viable option with moderate
sample sizes and/or moderately performing risk prediction models, assuming a
non-constant relative treatment effect plausible. RCS-3 is a better option with
more abundant sample size and when non-monotonic deviations from a constant
relative treatment effect and/or substantial treatment-related harms are
anticipated. Increasing the complexity of the RCS models by increasing the
number of knots does not improve benefit prediction. Using AIC for model
selection is attractive with larger sample size.

\newpage
# References
\setlength{\parindent}{-0.25in}
\setlength{\leftskip}{0.25in}
\noindent
<div id="refs"></div>
\setlength{\parindent}{0in}
\setlength{\leftskip}{0in}
\noindent
